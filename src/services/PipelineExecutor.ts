
import { VideoProject, PipelineStage, EngineConfig, VideoFormat, ScriptGenerationSnapshot } from "../types";
import { ProjectService } from "./ProjectService";
import { generateVideoScriptAndPrompts, rewriteTranscript, structureScript, generateSpeech } from "./geminiService";
import { PersistenceService } from "./PersistenceService";
import { ChannelProfile, StageDataMap } from "../types";
import { pcmToWav, getAudioDuration } from "../lib/audioUtils";
import { saveAudio } from "./AudioStorageService";

export class PipelineExecutor {
    constructor(
        private projectService: ProjectService,
        private persistence: PersistenceService,
        private getConfig: () => EngineConfig,
        private getProfile: (channelId: string) => ChannelProfile | undefined
    ) { }

    async processProject(project: VideoProject): Promise<VideoProject | void> {
        try {
            await this.projectService.updateProject(project.id, { status: "processing" });

            const config = this.getConfig();
            const profile = this.getProfile(project.channelId);

            if (!profile) {
                throw new Error(`Profile not found for channel ${project.channelId}`);
            }

            switch (project.currentStage) {
                case PipelineStage.REFERENCE:
                    return await this.processReferenceStage(project, config);
                case PipelineStage.SCRIPT:
                    return await this.processScriptStage(project, profile, config);
                case PipelineStage.AUDIO:
                    return await this.processAudioStage(project, profile, config);
                default:
                    console.log(`No auto-process defined for stage ${project.currentStage}`);
                    await this.projectService.updateProject(project.id, { status: "ready" });
                    break;
            }
        } catch (error) {
            console.error(`Pipeline execution failed for project ${project.id}:`, error);
            await this.projectService.updateProject(project.id, {
                status: "error",
                errorMessage: String(error),
            });
        }
    }

    // --- STAGE HANDLERS ---

    private async processReferenceStage(
        project: VideoProject,
        config: EngineConfig
    ): Promise<VideoProject> {
        const referenceData = project.stageData.reference;
        if (!referenceData) throw new Error("Dados de refer√™ncia ausentes");

        let transcript = referenceData.transcript?.trim() || '';

        if (!transcript) {
            const apifyKey = config.apiKeys.apify;
            if (!apifyKey) {
                throw new Error("Token da APIFY n√£o configurado. V√° em Configura√ß√µes e preencha o campo APIFY.");
            }

            console.log(`[Pipeline] üéØ Transcrevendo v√≠deo ${referenceData.videoId} via APIFY...`);
            const { transcribeVideo } = await import("../lib/youtubeMock");
            const result = await transcribeVideo(referenceData.videoId, apifyKey);
            transcript = result.transcript?.trim() || '';
            console.log(`[Pipeline] üìù APIFY retornou transcript com ${transcript.length} chars`);

            if (transcript) {
                await this.projectService.updateProject(project.id, {
                    stageData: {
                        ...project.stageData,
                        reference: { ...referenceData, transcript }
                    }
                });
            }
        }

        if (!transcript) {
            throw new Error("Transcri√ß√£o n√£o encontrada. O v√≠deo pode n√£o ter legendas habilitadas, ou o ator APIFY retornou vazio.");
        }

        console.log(`[Pipeline] ‚úÖ Transcri√ß√£o obtida (${transcript.length} chars). Aguardando aprova√ß√£o do usu√°rio.`);

        await this.projectService.updateProject(project.id, {
            status: 'review',
            stageData: {
                ...project.stageData,
                reference: { ...referenceData, transcript }
            }
        });

        return {
            ...project,
            status: 'review',
            stageData: { ...project.stageData, reference: { ...referenceData, transcript } }
        };
    }

    /**
     * ROTEIRO ‚Üí pr√≥ximo est√°gio
     * Pipeline de 2 prompts:
     *   P1 (Reescrita Magn√©tica) ‚Üí P2 (Estrutura√ß√£o Viral)
     * Grava ScriptGenerationSnapshot imut√°vel no v√≠deo.
     */
    private async processScriptStage(
        project: VideoProject,
        profile: ChannelProfile,
        config: EngineConfig
    ): Promise<VideoProject> {
        const referenceData = project.stageData.reference;
        const transcript = referenceData?.transcript;

        if (!transcript) {
            throw new Error("Transcri√ß√£o de refer√™ncia n√£o encontrada. Volte ao est√°gio Refer√™ncia.");
        }

        // Resolve model: channel-specific or global fallback
        const modelId = profile.scriptingModel || 'gemini-3-flash-preview';
        const provider = profile.scriptingProvider || config.providers.scripting || 'GEMINI';

        // Load active ChannelPrompt
        let rewritePrompt = '';
        let structurePrompt = '';
        let promptVersionId = '';

        if (profile.activePromptId) {
            try {
                const prompts = await this.persistence.loadChannelPrompts(profile.id);
                const active = prompts.find(p => p.id === profile.activePromptId);
                if (active) {
                    rewritePrompt = active.promptText;
                    structurePrompt = active.structurePromptText || '';
                    promptVersionId = active.id;
                    console.log(`[Pipeline] Usando ChannelPrompt ativo: ${active.id}`);
                }
            } catch (e) {
                console.warn('[Pipeline] Erro ao carregar ChannelPrompt, usando defaults:', e);
            }
        }

        // P1 ‚Äî Reescrita Magn√©tica
        console.log(`[Pipeline] ====== P1 ‚Äî Reescrita via ${provider}/${modelId} ======`);
        const p1Result = await rewriteTranscript(transcript, rewritePrompt, modelId, provider, config);
        console.log(`[Pipeline] P1 conclu√≠do: ${p1Result.caracteres} caracteres`);

        // P2 ‚Äî Estrutura√ß√£o Viral
        console.log(`[Pipeline] ====== P2 ‚Äî Estrutura√ß√£o via ${provider}/${modelId} ======`);
        const p2Result = await structureScript(p1Result.text, structurePrompt, modelId, provider, config);
        console.log(`[Pipeline] P2 conclu√≠do: title="${p2Result.title}"`);

        // Create immutable snapshot
        const snapshot: ScriptGenerationSnapshot = {
            modelId,
            modelProvider: provider,
            rewritePromptText: rewritePrompt,
            structurePromptText: structurePrompt,
            promptVersionId,
            generatedAt: new Date().toISOString(),
        };

        const scriptData: StageDataMap['script'] = {
            text: p1Result.text,
            wordCount: p1Result.text.split(/\s+/).length,
            promptUsed: promptVersionId || 'default',
            title: p2Result.title,
            description: p2Result.description,
            thumbText: p2Result.thumb_text,
            tags: p2Result.tags,
            generationSnapshot: snapshot,
            mode: 'auto'
        };

        return await this.projectService.advanceStage(project, { script: scriptData });
    }

    /**
     * √ÅUDIO ‚Äî Gera√ß√£o TTS
     * 1. L√™ o roteiro do P1 (script.text)
     * 2. Usa a voz configurada no perfil do canal
     * 3. Gera via Gemini TTS com retry
     * 4. Converte base64 PCM ‚Üí WAV
     * 5. Calcula dura√ß√£o e avan√ßa est√°gio
     */
    private async processAudioStage(
        project: VideoProject,
        profile: ChannelProfile,
        config: EngineConfig
    ): Promise<VideoProject> {
        const scriptData = project.stageData.script;
        if (!scriptData?.text) {
            throw new Error("Roteiro n√£o encontrado. Volte ao est√°gio Roteiro e processe novamente.");
        }

        const voiceId = profile.voiceProfile || 'Kore';
        console.log(`[Pipeline] ====== √ÅUDIO ‚Äî TTS com voz ${voiceId} ======`);
        console.log(`[Pipeline] Texto: ${scriptData.text.length} caracteres, ~${scriptData.wordCount} palavras`);

        // Gerar √°udio via Gemini TTS (com retry autom√°tico)
        const base64Pcm = await generateSpeech(scriptData.text, voiceId, config);
        if (!base64Pcm) {
            throw new Error("Falha na gera√ß√£o de √°udio: resposta vazia do TTS.");
        }

        // Converter para WAV blob URL (para calcular dura√ß√£o)
        const blobUrl = pcmToWav(base64Pcm);

        // Calcular dura√ß√£o do √°udio
        let duration: number | undefined;
        try {
            duration = await getAudioDuration(blobUrl);
            console.log(`[Pipeline] ‚úÖ √Åudio gerado: ${duration.toFixed(1)}s de dura√ß√£o`);
        } catch (e) {
            console.warn('[Pipeline] N√£o foi poss√≠vel calcular dura√ß√£o do √°udio:', e);
        }

        // Converter PCM para WAV Uint8Array e salvar no IndexedDB (evita QuotaExceeded do localStorage)
        const binaryString = atob(base64Pcm);
        const pcmBytes = new Uint8Array(binaryString.length);
        for (let i = 0; i < binaryString.length; i++) {
            pcmBytes[i] = binaryString.charCodeAt(i);
        }
        // Reutilizamos a l√≥gica de header WAV do pcmToWav, mas precisamos do Uint8Array raw
        // Para simplificar, vamos buscar o blob do blobUrl e salvar
        const blobResponse = await fetch(blobUrl);
        const wavArrayBuffer = await blobResponse.arrayBuffer();
        const wavData = new Uint8Array(wavArrayBuffer);
        await saveAudio(project.id, wavData);
        console.log(`[Pipeline] üíæ √Åudio salvo no IndexedDB (${(wavData.length / 1024).toFixed(0)} KB)`);

        const audioData: StageDataMap['audio'] = {
            fileUrl: `idb://${project.id}`,
            duration,
            provider: config.providers.tts || 'GEMINI',
            mode: 'auto',
        };

        return await this.projectService.advanceStage(project, { audio: audioData });
    }
}
